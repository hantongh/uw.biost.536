---
title: "BIOST 536 Homework "
author: "Hantong Hu"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
library(tidyverse)
knitr::opts_chunk$set(echo = F)
```

# Responses

1. Since both the periconceptual nutritional supplementation (E) and neural tube defects (D) can have an effect on birth (C), birth is therefore not a confounder but a collider. Adjusting for a collider induces association, which in this case causes bias to the result. More intuitively, limiting only to live births may cause the population to have more patients taking periconceptual nutritional supplementation and less patients having neural tube defects, which would affect the results.

```{r q1, warning=FALSE, message=FALSE, echo =FALSE}
## Q1
```

2. The DAG is presented as below. Dr. Ott should not treat GFR as a confounder because there is no backdoor path from lead poisoning to PKD.

### Figure 1. DAG addressing the scientific model for causation between lead poisoning and PKD

```{r q2, warning=FALSE, message=FALSE, echo =F}
## Q2
library(dagR)

dag1 <- dag.init(outcome=NULL,exposure=NULL, # these are never used
                 covs=c(1,1), # one element for each covariate (1=standard, 2=unmeasured)
                 arcs=c(0,2, # line from covariate #1 to exposure
                        0,1,
                        -1,2), # line from covariate #1 to outcome
                 x.name = "Lead poisoning",y.name = "Polycystic kidney disease ", # name of exposure and outcome
                 cov.names = c("Glomerular filtration rate","Kidney failure"),
                 symbols = c("LP", "GFR","KF","PKD"))

p <- dag.draw(dag1)
```

3. 

a. The ratio of sampling probabilities is 
$$\pi=\frac{P[Z=1|D=1]}{P[Z=1|D=0]}=\frac{1}{10\%/(1-10\%)}=9$$
The expected value of $\hat{\beta_0}$ is
$$\hat{\beta_0}=log(\pi)+logit(P[D|E=0, C=0])=log(9)+logit(P[D|E=0, C=0])$$

```{r q3a, warning=FALSE, message=FALSE, echo =F}
## Q3a
```

b. The ratio of sampling probabilities is 
$$\pi=\frac{P[Z=1|D=1]}{P[Z=1|D=0]}=\frac{1}{10\%/(1-10\%)\times9}=1$$
The expected value of $\hat{\beta_0}$ is
$$\hat{\beta_0}=log(\pi)+logit(P[D|E=0, C=0])=logit(P[D|E=0, C=0])$$
The expected value of $\hat{\beta_0}$ in this case equals to the value of population parameter. This makes sense because all of the controls are sampled in this case, thus making the study similar to a cohort study.

```{r q3b, warning=FALSE, message=FALSE, echo =F}
## Q3b
```

4. 

a. The scatterplot of X and D is shown below. A smooth curve is also plotted.

```{r q4a, warning=FALSE, message=FALSE, echo =F, fig.height=4, fig.width=5}
## Q4a
library(ggplot2)
X <- c(rep.int(0,30), rep.int(1,30), rep.int(2,30))
D <- c(rep.int(0,20), rep.int(1,10), rep.int(0,15), rep.int(1,15), rep.int(0,10), rep.int(1,20))
data.4 <- as.data.frame(cbind(X,D))

ggplot(data = data.4, aes(x=X, y=D)) + geom_jitter(alpha=0.4, width = 0.1, height = 0.05) +
  stat_smooth(method = "glm",method.args = list(family=binomial), se=F) +
  ggtitle("Figure 2. Scatter Plot of X and D for 90 people")
```

b. By fitting a logistic regression model of D to X, we get
$$logit(p)= -0.69+0.69\times{X}$$
We also put a table for parameter estimates, SE, and exponentiated CI for reference.

```{r q4b, warning=FALSE, message=FALSE, echo =F}
## Q4b
library(rigr)
mod4b <- regress("odds", D~X, data = data.4)
coef4 <- coef(mod4b)
knitr::kable(coef4[,c(1,3,5,6)], digits = 2, 
             caption = "Parameter estimates, SE, and exponentiated CI of fitted model (Q4)")
```

c. The probability of D for individuals with X=0 is
$$ P[D|X=0]=\frac{1}{1+e^{-(-0.69+0.69*0)}}=0.33 $$
This makes sense since for 30 patients with X=0, 1/3 has D=1, so $P[D|X=0]=1/3=0.33$.

```{r q4c, warning=FALSE, message=FALSE, echo =F}
## Q4c
```

d. The probability of D for individuals with X=1 is
$$ P[D|X=1]=\frac{1}{1+e^{-(-0.69+0.69*1)}}=0.5 $$
This makes sense since for 30 patients with X=1, 1/2 has D=1, so $P[D|X=1]=1/2=0.5$.

```{r q4d, warning=FALSE, message=FALSE, echo =F}
## Q4d
```

e. The probability of D for individuals with X=2 is
$$ P[D|X=2]=\frac{1}{1+e^{-(-0.69+0.69*2)}}=0.67 $$
This makes sense since for 30 patients with X=2, 2/3 has D=1, so $P[D|X=2]=2/3=0.67$.

```{r q4e, warning=FALSE, message=FALSE, echo =F}
## Q4e
```

f. The filled table is as below.
```{r q4f, warning=FALSE, message=FALSE, echo =F}
## Q4f
table4f <- matrix(nrow = 3, ncol = 4)
colnames(table4f) <- c("X", "p, probability of D", "odds of D", "log odds of D = logit(p)")
table4f[,1] <- c(0,1,2)
table4f[,2] <- c(1/3, 1/2, 2/3)
table4f[,4] <- c(-0.6931, 0, 0.6931)
table4f[,3] <- exp(table4f[,4])
knitr::kable(table4f, digits = 2, caption = "p, Odds of D, and log odds of D for each X")
```

g. When plotting logit(p) against X, the 3 points lie on one line $y=-0.69+0.69*X$.

```{r q4g, warning=FALSE, message=FALSE, echo =F, fig.height=4, fig.width=5}
## Q4g
ggplot(as.data.frame(table4f), aes(x=X, y=`log odds of D = logit(p)`))+
  geom_point()+geom_line()+
  ggtitle("Figure 3. Plot logit(p) against X")
```

5. By fitting a logistic regression model of D to X, we get
$$logit(p)= -0.69+0.69\times{X}$$
The table for parameter estimates, SE, and exponentiated CI are presented below. Compared to the regression model in Q4b, the parameter estimates are exactly the same, but the SE is much smaller, and the confidence interval is much narrower.

```{r q5, warning=FALSE, message=FALSE, echo =F}
## Q5
X <- c(rep.int(0,300), rep.int(1,300), rep.int(2,300))
D <- c(rep.int(0,200), rep.int(1,100), rep.int(0,150), rep.int(1,150), rep.int(0,100), rep.int(1,200))
data.5 <- as.data.frame(cbind(X,D))

mod5 <- regress("odds", D~X, data = data.5)
coef5 <- coef(mod5)
knitr::kable(coef5[,c(1,3,5,6)], digits = 2, 
             caption = "Parameter estimates, SE, and exponentiated CI of fitted model (Q5)")
```

6. 

a. The scatterplot of X and D is shown below. A smooth curve is also plotted.

```{r q6a, warning=FALSE, message=FALSE, echo =F, fig.height=4, fig.width=5}
## Q6a
X <- c(rep.int(-1,30), rep.int(0,30), rep.int(1,30), rep.int(2,30), rep.int(3,30))
D <- c(rep.int(0,30), rep.int(0,20), rep.int(1,10), 
       rep.int(0,15), rep.int(1,15), rep.int(0,10), 
       rep.int(1,20), rep.int(1,30))
data.6 <- as.data.frame(cbind(X,D))

ggplot(data = data.6, aes(x=X, y=D)) + geom_jitter(alpha=0.4, width = 0.1, height = 0.05) +
  stat_smooth(method = "glm",method.args = list(family=binomial), se=F) +
  ggtitle("Figure 4. Scatter Plot of X and D for 150 people")
```

b. By fitting a logistic regression model of D to X, we get
$$logit(p)= -1.35+1.35\times{X}$$
We also put a table for parameter estimates, SE, and exponentiated CI for reference.

```{r q6b, warning=FALSE, message=FALSE, echo =F}
## Q6b
mod6b <- regress("odds", D~X, data = data.6)
coef6 <- coef(mod6b)
knitr::kable(coef6[,c(1,3,5,6)], digits = 2,
caption = "Parameter estimates, SE, and exponentiated CI of fitted model (Q6)")
```

c. The probability of D for individuals with X=0 is
$$ P[D|X=0]=\frac{1}{1+e^{-(-1.35+1.35*0)}}=0.21 $$
If we fit a logistic regression on this data completely based the "MLE target" this data gives, we will have the same striaght line as we did in Q4. However, since logistic regression cannot have a probability of 0 and 1, the regression line for this data cannot be straight. Thus, to compromise for the S curve, the $P[D|X=0]$ will be lower than what we calculated from Q4.

```{r q6c, warning=FALSE, message=FALSE, echo =F}
## Q6c
```

d. The probability of D for individuals with X=0 is
$$ P[D|X=1]=\frac{1}{1+e^{-(-1.35+1.35*1)}}=0.5 $$
This value is the same as in Q4D because, even if we compromise the data values for the S curve, the point in the middle (X=1 is the center of X=-1 to X=3) is not affected and therefore does not change in value.

```{r q6d, warning=FALSE, message=FALSE, echo =F}
## Q6d
```

\pagebreak

# Code
```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```